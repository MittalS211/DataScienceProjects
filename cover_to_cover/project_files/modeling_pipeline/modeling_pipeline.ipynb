{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling pipeline\n",
    "This notebook contians all functions and additional documentation for the higher order pipeline function run_save_models, This pipeline allows for convenient iteration functionality for exploring the book-cover dataset with one-to-one genre classification and testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully!\n",
      "pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "# boilerplate dependencies for codebase\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import keras\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''Define New Class to save epoch runtime output from Keras Callback objects'''\n",
    "\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "\n",
    "\n",
    "def load_images(data_path, categories, \n",
    "                IMG_SIZE = 50, augment=None, \n",
    "                grayscale=True):\n",
    "    \"\"\"function to load images via list of sub directories, \n",
    "    with options to adjust image size, color and appying augmentation via flipped images \"\"\"\n",
    "    data = list()\n",
    "    target = list()\n",
    "    errors = 0\n",
    "    for i, category in enumerate(categories): \n",
    "        filepaths = []\n",
    "        images_dir = data_path+category\n",
    "        for root, dirs, files in os.walk(images_dir):\n",
    "             for file in files:\n",
    "                filepaths.append((os.path.join(root, file)))\n",
    "\n",
    "        filepaths = [path for path in filepaths if path.endswith('jpg')]\n",
    "        \n",
    "        for path in filepaths:\n",
    "            try:\n",
    "                img_path = path\n",
    "\n",
    "                if grayscale ==True:\n",
    "                    img_data = cv2.imread(img_path, 0)\n",
    "                \n",
    "                else:\n",
    "                    img_data = cv2.imread(img_path, 1) # read image in color\n",
    "                    img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB) # convert to RGB color mapping\n",
    "\n",
    "\n",
    "                img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
    "                #print(img_data.shape)\n",
    "                \n",
    "                # normalize pixels \n",
    "                data.append(img_data)\n",
    "                target.append(i)\n",
    "                \n",
    "                if augment:\n",
    "                    data.append(np.fliplr(img_data))\n",
    "                    target.append(i)\n",
    "                \n",
    "            except Exception as e:\n",
    "                errors +=1 # track errors\n",
    "                continue\n",
    "    print(\"{} images unable to be loaded.\".format(errors))\n",
    "    return (data,target)\n",
    "\n",
    "def process_data(X, y, n_classes,  IMG_SIZE=50, grayscale=True):\n",
    "    '''Function to handling preprocessing images '''\n",
    "    new_X = np.array(X) / 255 #normalize pixels\n",
    "    \n",
    "    if grayscale==True:\n",
    "        \n",
    "        new_X = new_X.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "        \n",
    "    else:\n",
    "        new_X = new_X.reshape(-1,IMG_SIZE,IMG_SIZE,3) #format data with color channels\n",
    "\n",
    "    \n",
    "    new_y = keras.utils.np_utils.to_categorical(y, n_classes)\n",
    "    \n",
    "    return (new_X, new_y)\n",
    "\n",
    "def compile_and_fit(model, fit_params, loss= 'categorical_crossentropy', opt=RMSprop(), metrics=['accuracy'], log_times=False):\n",
    "    \"\"\"function to compile and fit neural networks in one step, \n",
    "    \n",
    "       model: keras model to compile \n",
    "       fit_params: dictionary of model fit parameters mapped to dict keys: ['X_train', 'y_train', 'batch_size', 'epochs', 'validation_data']\n",
    "       loss: loss function\n",
    "       opt: optimizer\n",
    "       metrics: model metrics\n",
    "       Log_times: boolean, if True function returns list of runtimes of each epoch in the model, depends on *TimeHistory Class* default False\n",
    "       \"\"\"\n",
    "    \n",
    "    model_copy = model\n",
    "    model_copy.compile(loss=loss,\n",
    "              optimizer=opt,\n",
    "              metrics=metrics)\n",
    "    if log_times==False:\n",
    "        model_history = model_copy.fit(fit_params[\"X_train\"], fit_params[\"y_train\"], batch_size = fit_params[\"batch_size\"], \n",
    "                  epochs = fit_params[\"epochs\"], \n",
    "               validation_data = fit_params[\"validation_data\"], verbose = 2)\n",
    "        return model_history\n",
    "    \n",
    "    else:\n",
    "        time_callback = TimeHistory()\n",
    "        model_history = model_copy.fit(fit_params[\"X_train\"], fit_params[\"y_train\"], batch_size = fit_params[\"batch_size\"], \n",
    "              callbacks = [time_callback], epochs = fit_params[\"epochs\"], \n",
    "           validation_data = fit_params[\"validation_data\"], verbose = 2)\n",
    "        return model_history, time_callback.times\n",
    "\n",
    "# store model history as csv for easy retrieval\n",
    "def save_model_history(model_callback,filename, subdir=None, times=None):   \n",
    "    df = pd.DataFrame.from_dict(model_callback.history)\n",
    "\n",
    "    if times:\n",
    "        df['epoch_runtime'] = times\n",
    "    if subdir:\n",
    "        filepath ='model_history/{}/{}.csv'.format(subdir, filename)\n",
    "    else:\n",
    "        filepath = 'model_history/{}.csv'.format(filename)\n",
    "    df.to_csv(filepath)\n",
    "    print('\\nmodel history saved at {}'.format(filepath))\n",
    "    return filepath\n",
    "\n",
    "def plot_model_history(csv_file, model_name):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    train_loss = df['loss']\n",
    "    val_loss   = df['val_loss']\n",
    "    train_acc  = df['acc']\n",
    "    val_acc    = df['val_acc']\n",
    "    xc         = range(df.shape[0])\n",
    "       \n",
    "    label = csv_file.split('/')[-1][:-4]\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.suptitle('{} : {}'.format(model_name, label))\n",
    "    plt.title('Accuracy')\n",
    "    \n",
    "    plt.plot(xc, train_acc)\n",
    "    plt.plot(xc, val_acc)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'test'])\n",
    "\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.suptitle('{} : {}'.format(model_name, label))\n",
    "    plt.title('Loss')\n",
    "    \n",
    "    plt.ylim(bottom=train_loss.min(), top=1)\n",
    "    plt.plot(xc, train_loss)\n",
    "    plt.plot(xc, val_loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "print(\"Helper functions loaded successfully!\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def run_save_models(models, model_names, labels, params, filepath, IMG_SIZE=50, aug=False, grayscale=True):\n",
    "    '''pipeline function to run models, save the output to a csv file,\n",
    "       also return the file path and confusion matrix for further exploration of results'''\n",
    "    \n",
    "    if aug == False:\n",
    "        aug = None\n",
    "    \n",
    "    if grayscale==True:\n",
    "        X, y = load_images(filepath, categories=labels, IMG_SIZE = IMG_SIZE, augment = aug, grayscale=True)\n",
    "        X, y = process_data(X, y, n_classes=len(labels), IMG_SIZE=IMG_SIZE, grayscale=True)\n",
    "    else:\n",
    "        X, y = load_images(filepath, categories=labels, IMG_SIZE = IMG_SIZE, augment = aug, grayscale=False)\n",
    "        X, y = process_data(X, y, n_classes=len(labels), IMG_SIZE=IMG_SIZE, grayscale=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state = 0)\n",
    "    \n",
    "    \n",
    "    params['X_train'] = X_train\n",
    "    params['y_train'] = y_train\n",
    "    params['validation_data'] = (X_test, y_test)\n",
    "    files = []\n",
    "    cms = []\n",
    "    for model, model_name in zip(models, model_names):\n",
    "\n",
    "        model_history, runtimes = compile_and_fit(model, params, opt=Adam(),log_times=True)\n",
    "        print(model.summary())\n",
    "        if model_name not in os.listdir('model_history/'):\n",
    "            os.mkdir('model_history/{}'.format(model_name))\n",
    "\n",
    "        files.append(save_model_history(model_history, times=runtimes,subdir=model_name\\\n",
    "                                         , filename=\"{} or {}\".format(labels[0],labels[1])))\n",
    "        \n",
    "        #generate confusion matrix\n",
    "        y_pred = model.predict_classes(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test[:, 1], y_pred)\n",
    "        \n",
    "        cms.append(cm)\n",
    "    return files, cms\n",
    "\n",
    "print(\"pipeline ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
